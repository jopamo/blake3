#!/usr/bin/env bash
# bench-b3sum-llm.sh â€” compare C vs Rust b3sum
#
# FEATURES:
#  - Valid Measurements: Uses '-N' (direct exec) for large files to avoid shell noise.
#  - LLM-Friendly: Prints a clean Markdown summary table to STDOUT.
#  - Detailed Logging: Saves all generation/diff/strace noise to 'bench_detail.log'.
#  - Strict Correctness: Retains full Python normalization and diff checks.

set -u
set -o pipefail

####################################
# Logging Setup
####################################

LOGFILE="bench_detail.log"
rm -f "$LOGFILE"

# 1. Save the original STDOUT to File Descriptor 3
exec 3>&1

# 2. Redirect standard STDOUT/STDERR to the log file
exec 1>>"$LOGFILE"
exec 2>&1

# Function: Output to user (FD3) AND log file
say() {
  echo "$@" >&3
  echo "$@"
}

# Function: Output to log file only (for noise)
log() {
  echo "$@"
}

say "ðŸ“ Detailed execution log saved to: $LOGFILE"

####################################
# Config
####################################

C_IMPL="./build-meson-release/b3sum"
R_IMPL="/usr/bin/b3sum_rust"

RUNS=10
WARMUP=2
SIZES_MIB=(4 8 16 32 64 128 256 512 1024)

SMALLFILES_COUNT=5000
SMALLFILE_MIN=1024
SMALLFILE_MAX=4096

# Hyperfine options
HYPERFINE_OPTS=(
  "--runs" "$RUNS"
  "--warmup" "$WARMUP"
  "--style" "none"
  "--sort" "command"
)

# Check for shuffle support
if hyperfine --help 2>/dev/null | grep -qE '(^|[[:space:]])--shuffle([[:space:]]|,|$)'; then
  HYPERFINE_OPTS+=("--shuffle")
fi

####################################
# Checks & Helpers
####################################

require_bin() {
  if ! command -v "$1" >/dev/null 2>&1; then
    say "ðŸ”¥ Error: need $1"
    exit 1
  fi
}

require_bin hyperfine
require_bin python3
require_bin stat
require_bin awk
require_bin dd
require_bin find
require_bin sort
require_bin diff

CAN_DROP_CACHE=false
if [[ $(id -u) -eq 0 ]] && [[ -w /proc/sys/vm/drop_caches ]]; then
  CAN_DROP_CACHE=true
fi

####################################
# Python Helper: Parse JSON -> Markdown
####################################

print_markdown_row() {
  local json_file="$1"
  local label="$2"

  # We use python3 to parse the JSON and print a formatted row to FD3
  python3 -c "
import json, sys

try:
    with open('$json_file') as f:
        data = json.load(f)

    results = {r['command']: r for r in data['results']}

    # Match commands containing 'C' and 'Rust' (case insensitive logic if needed)
    c_res = next((v for k,v in results.items() if 'C' in k), None)
    r_res = next((v for k,v in results.items() if 'Rust' in k), None)

    if c_res and r_res:
        c_mean = c_res['mean'] * 1000
        r_mean = r_res['mean'] * 1000
        ratio = c_mean / r_mean

        # Output: | Label | C (ms) | Rust (ms) | Ratio |
        print(f'| {sys.argv[1]} | {c_mean:7.3f} | {r_mean:7.3f} | {ratio:5.3f} |')
    else:
        print(f'| {sys.argv[1]} | error | error | error |')
except Exception as e:
    print(f'| {sys.argv[1]} | error | error | {e} |')
" "$label" >&3
}

####################################
# Data Generation
####################################

SANDBOX="$(mktemp -d /tmp/b3bench.XXXXXX)"
trap 'rm -rf "$SANDBOX"' EXIT

say "âš™ï¸  Generating test data (silently)..."

gen_big_file() {
  local path="$1"
  local mib="$2"
  if command -v fallocate >/dev/null 2>&1; then
    fallocate -l "$((mib * 1024 * 1024))" "$path"
    dd if=/dev/urandom of="$path" bs=1M count=1 seek=$((mib/2)) conv=notrunc 2>/dev/null || true
  else
    dd if=/dev/urandom of="$path" bs=1M count="$mib" 2>/dev/null
  fi
}

declare -a FILES=()
for sz in "${SIZES_MIB[@]}"; do
  f="$SANDBOX/file_${sz}MiB.bin"
  log "Generating $f..."
  gen_big_file "$f" "$sz"
  FILES+=("$f")
done

SMALLDIR="$SANDBOX/smallfiles"
mkdir -p "$SMALLDIR"
log "Generating tiny files in $SMALLDIR..."
for i in $(seq 1 $SMALLFILES_COUNT); do
    dd if=/dev/urandom of="$SMALLDIR/f_$i" bs=$((1024 + RANDOM % 3000)) count=1 2>/dev/null
done

####################################
# Correctness Verification
####################################

say "ðŸ§ª Verifying correctness..."

# 1. Large Files
for FILE in "${FILES[@]}"; do
  HC=$("$C_IMPL" "$FILE" | awk '{print $1}')
  HR=$("$R_IMPL" "$FILE" | awk '{print $1}')
  log "Check $FILE: C=$HC R=$HR"
  if [[ "$HC" != "$HR" ]]; then
    say "ðŸ”¥ Hash mismatch on $FILE"
    say "C: $HC"
    say "R: $HR"
    exit 1
  fi
done

# 2. Tiny Files (Full Normalization)
C_RAW="$SANDBOX/c_tiny.raw"
R_RAW="$SANDBOX/r_tiny.raw"
C_NORM="$SANDBOX/c_tiny.norm"
R_NORM="$SANDBOX/r_tiny.norm"

find "$SMALLDIR" -type f -print0 | sort -z | xargs -0 "$C_IMPL" > "$C_RAW"
find "$SMALLDIR" -type f -print0 | sort -z | xargs -0 "$R_IMPL" > "$R_RAW"

# Python Normalizer (Embedded)
normalize_sum_output() {
  python3 - "$1" "$2" "$3" <<'PY'
import sys
inp, outp, strip_prefix = sys.argv[1], sys.argv[2], sys.argv[3]
def norm_path(p):
    if strip_prefix and p.startswith(strip_prefix): p = p[len(strip_prefix):]
    while p.startswith("./"): p = p[2:]
    return p
lines = []
with open(inp, "r", errors="replace") as f:
    for line in f:
        parts = line.strip().split()
        if len(parts) >= 2:
            h = parts[0] if parts[0] != "BLAKE3" else parts[1]
            p = parts[1] if parts[0] != "BLAKE3" else parts[2]
            lines.append(f"{h} {norm_path(p)}")
with open(outp, "w") as f:
    for l in lines: f.write(l + "\n")
PY
}

normalize_sum_output "$C_RAW" "$C_NORM" "$SANDBOX/"
normalize_sum_output "$R_RAW" "$R_NORM" "$SANDBOX/"
sort -o "$C_NORM" "$C_NORM"
sort -o "$R_NORM" "$R_NORM"

if ! diff -u "$C_NORM" "$R_NORM" >/dev/null 2>&1; then
  say "ðŸ”¥ Tiny file mismatch!"
  # Print the diff to the user so they can see why
  diff -u "$C_NORM" "$R_NORM" | head -n 20 >&3
  exit 1
fi

say "âœ… All checks passed."
echo "" >&3

####################################
# Benchmarking
####################################

pre_cmd="sync"
if $CAN_DROP_CACHE; then
  pre_cmd="sync; echo 3 > /proc/sys/vm/drop_caches"
fi

# Print Markdown Header
echo "## ðŸš€ Benchmark Results" >&3
echo "" >&3
echo "| Workload | C (ms) | Rust (ms) | Ratio (C/R) |" >&3
echo "| :--- | :--- | :--- | :--- |" >&3

# 1. Large Files
for FILE in "${FILES[@]}"; do
  SIZE_MIB=$(stat -c %s "$FILE" | awk '{print $1/1024/1024}')
  LABEL="${SIZE_MIB} MiB"
  JSON_OUT="$SANDBOX/hf_big_${SIZE_MIB}.json"

  # FIX: Removed '--' separators.
  # Hyperfine will correctly map option -n "Name" to the next positional arg.
  hyperfine "${HYPERFINE_OPTS[@]}" \
    -N \
    --prepare "$pre_cmd" \
    --export-json "$JSON_OUT" \
    --command-name "C"    "$C_IMPL $FILE" \
    --command-name "Rust" "$R_IMPL $FILE"

  print_markdown_row "$JSON_OUT" "$LABEL"
done

# 2. Tiny Files
LABEL="TinyFiles (${SMALLFILES_COUNT})"
JSON_OUT="$SANDBOX/hf_tiny.json"

# Rust requires shell for the find|xargs pipeline, so no -N here.
hyperfine "${HYPERFINE_OPTS[@]}" \
  --prepare "$pre_cmd" \
  --export-json "$JSON_OUT" \
  --command-name "C"    "find '$SMALLDIR' -type f -print0 | sort -z | xargs -0 '$C_IMPL' >/dev/null" \
  --command-name "Rust" "find '$SMALLDIR' -type f -print0 | sort -z | xargs -0 '$R_IMPL' >/dev/null"

print_markdown_row "$JSON_OUT" "$LABEL"

say ""
say "âœ¨ Done. Full verbose log in: $LOGFILE"
